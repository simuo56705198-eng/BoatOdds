import streamlit as st
import requests
import json
import re
from bs4 import BeautifulSoup
from datetime import datetime

# --- åˆæœŸè¨­å®š ---
st.set_page_config(page_title="Real-Time Physics Trader v2.2", layout="wide")
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
JCD_MAP = {
    "æ¡ç”Ÿ": "01", "æˆ¸ç”°": "02", "æ±Ÿæˆ¸å·": "03", "å¹³å’Œå³¶": "04", "å¤šæ‘©å·": "05",
    "æµœåæ¹–": "06", "è’²éƒ¡": "07", "å¸¸æ»‘": "08", "æ´¥": "09",
    "ä¸‰å›½": "10", "ã³ã‚ã“": "11", "ä½ä¹‹æ±Ÿ": "12", "å°¼å´": "13",
    "é³´é–€": "14", "ä¸¸äº€": "15",
    "å…å³¶": "16", "å®®å³¶": "17", "å¾³å±±": "18", "ä¸‹é–¢": "19",
    "è‹¥æ¾": "20", "èŠ¦å±‹": "21", "ç¦å²¡": "22", "å”æ´¥": "23", "å¤§æ‘": "24"
}

def extract_float(text):
    m = re.search(r'[\d\.]+', text)
    return float(m.group()) if m else 0.0

# --- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ç¾¤ (å…ƒãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Œå…¨å¾©å…ƒ) ---

def get_racelist(jcd, rno, hd, race_data):
    url = f"https://www.boatrace.jp/owpc/pc/race/racelist?rno={rno}&jcd={jcd}&hd={hd}"
    res = requests.get(url, headers=HEADERS)
    res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')
    tbodies = soup.select('.table1.is-tableFixed__3rdadd tbody.is-fs12')
    if not tbodies: return
    for tbody in tbodies:
        tds = tbody.find_all('tr')[0].find_all('td')
        if len(tds) < 8: continue
        boat_no = str(int(tds[0].text.strip()))
        name = tbody.select_one('.is-fs18.is-fBold').text.strip().replace('\u3000', ' ')
        class_rank = tbody.select_one('.is-fColor1').text.strip() if tbody.select_one('.is-fColor1') else ""
        st_list = [x.strip() for x in tds[3].text.split('\n') if x.strip()]
        mot = [x.strip() for x in tds[6].text.split('\n') if x.strip()]
        race_data["racelist"][boat_no].update({
            "name": name, "class": class_rank, 
            "motor_no": mot[0] if mot else '-', "motor_2ren": mot[1] if len(mot)>1 else '-', 
            "avg_st": extract_float(st_list[-1]) if st_list else 0.0
        })

def get_beforeinfo(jcd, rno, hd, race_data):
    url = f"https://www.boatrace.jp/owpc/pc/race/beforeinfo?rno={rno}&jcd={jcd}&hd={hd}"
    res = requests.get(url, headers=HEADERS)
    res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')
    
    env = {"weather": "ä¸æ˜", "wind_direction": "ç„¡é¢¨", "wind_speed": 0.0, "temperature": 0.0, "water_temp": 0.0, "wave_height": 0.0}
    
    t_el = soup.select_one('.is-direction .weather1_bodyUnitLabelData')
    if t_el: env['temperature'] = extract_float(t_el.text)
    
    w_el = soup.select_one('.is-weather .weather1_bodyUnitLabelTitle')
    if w_el: env['weather'] = w_el.text.strip()
    
    ws_el = soup.select_one('.is-wind .weather1_bodyUnitLabelData')
    if ws_el: env['wind_speed'] = extract_float(ws_el.text)
    
    wt_el = soup.select_one('.is-waterTemperature .weather1_bodyUnitLabelData')
    if wt_el: env['water_temp'] = extract_float(wt_el.text)
    
    wh_el = soup.select_one('.is-wave .weather1_bodyUnitLabelData')
    if wh_el: env['wave_height'] = extract_float(wh_el.text)

    wd_img = soup.select_one('.is-windDirection .weather1_bodyUnitImage')
    if wd_img and wd_img.has_attr('class'):
        for cls in wd_img['class']:
            if cls.startswith('is-wind') and cls != 'is-windDirection':
                num = cls.replace('is-wind', '')
                if num.isdigit():
                    dir_map = {1: "è¿½ã„é¢¨", 2: "å³æ–œã‚è¿½ã„é¢¨", 3: "å³æ–œã‚è¿½ã„é¢¨", 4: "å³æ–œã‚è¿½ã„é¢¨", 5: "å³æ¨ªé¢¨", 9: "å‘ã‹ã„é¢¨", 13: "å·¦æ¨ªé¢¨", 14: "å·¦æ–œã‚è¿½ã„é¢¨", 15: "å·¦æ–œã‚è¿½ã„é¢¨", 16: "å·¦æ–œã‚è¿½ã„é¢¨"}
                    env['wind_direction'] = dir_map.get(int(num), "æ–œã‚é¢¨")
    
    if env['wind_speed'] == 0.0: env['wind_direction'] = "ç„¡é¢¨"
    race_data["environment"] = env

    for tbody in soup.select('.table1 tbody.is-fs12'):
        tds = tbody.find_all('tr')[0].find_all('td')
        if len(tds) < 6: continue
        boat_no = str(int(tds[0].text.strip()))
        race_data["racelist"][boat_no].update({
            "exhibition_time": extract_float(tds[4].text),
            "tilt": extract_float(tds[5].text)
        })

def get_3_combo_odds(jcd, rno, hd, is_trio, race_data):
    odds_type = 'odds3f' if is_trio else 'odds3t'
    key_name = '3é€£è¤‡' if is_trio else '3é€£å˜'
    sep = '=' if is_trio else '-'
    url = f"https://www.boatrace.jp/owpc/pc/race/{odds_type}?rno={rno}&jcd={jcd}&hd={hd}"
    res = requests.get(url, headers=HEADERS); res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')
    tbody = soup.select_one('tbody.is-p3-0')
    if not tbody: return
    current_snd, rem_rowspan = [None]*6, [0]*6
    for row in tbody.select('tr'):
        tds = row.find_all('td'); td_idx = 0
        for col_idx in range(6):
            if td_idx >= len(tds): break
            if rem_rowspan[col_idx] == 0:
                snd_td = tds[td_idx]; td_idx += 1
                trd_td = tds[td_idx] if td_idx < len(tds) else None; td_idx += 1
                odds_td = tds[td_idx] if td_idx < len(tds) else None; td_idx += 1
                current_snd[col_idx], rem_rowspan[col_idx] = snd_td, int(snd_td.get('rowspan', 1)) if snd_td else 1
            else:
                snd_td = current_snd[col_idx]
                trd_td = tds[td_idx] if td_idx < len(tds) else None; td_idx += 1
                odds_td = tds[td_idx] if td_idx < len(tds) else None; td_idx += 1
            rem_rowspan[col_idx] -= 1
            if snd_td and trd_td and odds_td and "is-disabled" not in snd_td.get('class', []):
                odds_val = extract_float(odds_td.text)
                if odds_val > 0:
                    combo = f"{col_idx + 1}{sep}{snd_td.text.strip()}{sep}{trd_td.text.strip()}"
                    race_data["odds"][key_name][combo] = odds_val

def get_2_combo_odds(jcd, rno, hd, race_data):
    url = f"https://www.boatrace.jp/owpc/pc/race/odds2tf?rno={rno}&jcd={jcd}&hd={hd}"
    res = requests.get(url, headers=HEADERS); res.encoding = 'utf-8'
    tbodies = BeautifulSoup(res.text, 'html.parser').select('tbody.is-p3-0')
    if len(tbodies) > 0:
        for row in tbodies[0].select('tr'):
            tds = row.find_all('td')
            for c in range(6):
                if c*2+1 < len(tds) and "is-disabled" not in tds[c*2].get('class', []):
                    race_data["odds"]["2é€£å˜"][f"{c+1}-{tds[c*2].text.strip()}"] = extract_float(tds[c*2+1].text)
    if len(tbodies) > 1:
        for row in tbodies[1].select('tr'):
            tds = row.find_all('td')
            for c in range(6):
                if c*2+1 < len(tds) and "is-disabled" not in tds[c*2].get('class', []):
                    race_data["odds"]["2é€£è¤‡"][f"{c+1}={tds[c*2].text.strip()}"] = extract_float(tds[c*2+1].text)

# --- UIæ§‹ç¯‰ ---
st.title("ğŸš€ Real-Time Physics Trader v2.2")
st.caption("Deterministic Void & Wake Rejection Analysis Engine")

with st.sidebar:
    st.header("Race Settings")
    input_jcd = st.selectbox("é–‹å‚¬å ´", list(JCD_MAP.keys()))
    target_rno = st.number_input("ãƒ¬ãƒ¼ã‚¹ç•ªå·(R)", 1, 12, 12)
    target_date = st.date_input("æ—¥ä»˜", datetime.now()).strftime('%Y%m%d')
    execute = st.button("ç‰©ç†è§£æã‚¨ãƒ³ã‚¸ãƒ³èµ·å‹•")

if execute:
    target_jcd = JCD_MAP[input_jcd]
    race_data = {
        "metadata": {"date": target_date, "stadium": input_jcd, "race_number": f"{target_rno}R"},
        "environment": {},
        "racelist": {str(i): {} for i in range(1, 7)},
        "odds": {"3é€£å˜": {}, "3é€£è¤‡": {}, "2é€£å˜": {}, "2é€£è¤‡": {}, "æ‹¡é€£è¤‡": {}, "å˜å‹": {}, "è¤‡å‹": {}}
    }

    with st.spinner("æµä½“ãƒ‡ãƒ¼ã‚¿ãŠã‚ˆã³ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­..."):
        get_racelist(target_jcd, target_rno, target_date, race_data)
        get_beforeinfo(target_jcd, target_rno, target_date, race_data)
        get_3_combo_odds(target_jcd, target_rno, target_date, False, race_data) # 3é€£å˜
        get_3_combo_odds(target_jcd, target_rno, target_date, True, race_data)  # 3é€£è¤‡
        get_2_combo_odds(target_jcd, target_rno, target_date, race_data)        # 2é€£å˜è¤‡

    # --- ç‰©ç†åˆ¤å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  (å›ºæœ‰ãƒ­ã‚¸ãƒƒã‚¯) ---
    st.header("ğŸ›¡ï¸ Physics Analysis Report")
    
    # çŠ¶æ…‹åˆ¤å®šç”¨ãƒ•ãƒ©ã‚°
    void_flags = []
    wake_rejection = []

    cols = st.columns(6)
    for i in range(1, 7):
        b = race_data["racelist"][str(i)]
        with cols[i-1]:
            st.metric(f"{i}å·è‰‡", f"{b.get('exhibition_time', 0)}s")
            st.caption(f"{b.get('name', 'ä¸æ˜')} ({b.get('class', '-')})")
            
            # ãƒ­ã‚¸ãƒƒã‚¯1: Deterministic Void
            if i < 6:
                st_diff = b.get('avg_st', 0) - race_data["racelist"][str(i+1)].get('avg_st', 0)
                if abs(st_diff) >= 0.08:
                    st.error("âš ï¸ Void Detected")
                    void_flags.append(f"{i}-{i+1}é–“")

            # ãƒ­ã‚¸ãƒƒã‚¯3: Wake Rejection (èˆªè·¡æ‹’çµ¶)
            if i > 1:
                inner_ex = race_data["racelist"][str(i-1)].get('exhibition_time', 9.9)
                ex_diff = inner_ex - b.get('exhibition_time', 0)
                if ex_diff >= 0.07:
                    st.info("ğŸŒŠ Wake Rejection")
                    wake_rejection.append(f"{i}å·è‰‡ã«ã‚ˆã‚‹çªç ´")
                elif ex_diff <= 0.06 and b.get('class') == 'A1':
                    st.success("âš¡ A1 Breakthrough")

    # --- ã‚µãƒãƒªè¡¨ç¤º ---
    st.divider()
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("Environment")
        st.table([race_data["environment"]])
    with c2:
        st.subheader("Physics Log")
        if void_flags: st.write(f"ã€çœŸç©ºã€‘{', '.join(void_flags)}")
        if wake_rejection: st.write(f"ã€èˆªè·¡æ‹’çµ¶ã€‘{', '.join(wake_rejection)}")
        if not void_flags and not wake_rejection: st.write("ç‰¹ç­†ã™ã¹ãç‰©ç†å¹²æ¸‰ãªã—")

    # --- Raw Data (JSONå½¢å¼) ---
    st.subheader("Raw AI Data (JSON)")
    st.json(race_data)

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    json_str = json.dumps(race_data, ensure_ascii=False, indent=2)
    st.download_button("JSONã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", json_str, file_name=f"{target_date}_{input_jcd}_{target_rno}R.json")
