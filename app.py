import streamlit as st
import requests
import json
import re
from bs4 import BeautifulSoup
from datetime import datetime

# --- åˆæœŸè¨­å®š ---
st.set_page_config(page_title="Real-Time Physics Trader v2.2", layout="wide")
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
JCD_MAP = {
    "æ¡ç”Ÿ": "01", "æˆ¸ç”°": "02", "æ±Ÿæˆ¸å·": "03", "å¹³å’Œå³¶": "04", "å¤šæ‘©å·": "05",
    "æµœåæ¹–": "06", "è’²éƒ¡": "07", "å¸¸æ»‘": "08", "æ´¥": "09", "ä¸‰å›½": "10",
    "ã³ã‚ã“": "11", "ä½ä¹‹æ±Ÿ": "12", "å°¼å´": "13", "é³´é–€": "14", "ä¸¸äº€": "15",
    "å…å³¶": "16", "å®®å³¶": "17", "å¾³å±±": "18", "ä¸‹é–¢": "19", "è‹¥æ¾": "20",
    "èŠ¦å±‹": "21", "ç¦å²¡": "22", "å”æ´¥": "23", "å¤§æ‘": "24"
}

def extract_float(text):
    if not text: return 0.0
    m = re.search(r'[\d\.]+', str(text))
    return float(m.group()) if m else 0.0

# --- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»ã‚¨ãƒ³ã‚¸ãƒ³ ---

def get_racelist(jcd, rno, hd, race_data):
    url = f"https://www.boatrace.jp/owpc/pc/race/racelist?rno={rno}&jcd={jcd}&hd={hd}"
    res = requests.get(url, headers=HEADERS); res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')
    
    # å‡ºèµ°è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®å„è¡Œã‚’è§£æ
    tbodies = soup.select('.table1.is-tableFixed__3rdadd tbody.is-fs12')
    for tbody in tbodies:
        tds = tbody.find_all('tr')[0].find_all('td')
        if len(tds) < 3: continue
        
        # è‰‡ç•ªã®å–å¾— (å…¨è§’æ•°å­—ã«ã‚‚å¯¾å¿œ)
        b_no_raw = tds[0].text.strip()
        b_no_match = re.search(r'[1-6ï¼‘-ï¼–]', b_no_raw)
        if not b_no_match: continue
        # å…¨è§’ã‚’åŠè§’ã«å¤‰æ›ã—ã¦æ•°å€¤åŒ–
        b_no = str(int(b_no_match.group().translate(str.maketrans('ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–', '123456'))))

        # ç´šåˆ¥ï¼ˆã‚¯ãƒ©ã‚¹ï¼‰ã®å–å¾—ãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£
        # ã‚¯ãƒ©ã‚¹æƒ…å ±ãŒå…¥ã£ã¦ã„ã‚‹ div (is-fs11) å†…ã® span ã‚’å–å¾—
        class_info_div = tbody.select_one('div.is-fs11')
        rank = ""
        if class_info_div:
            rank_span = class_info_div.select_one('span')
            if rank_span:
                rank = rank_span.text.strip()

        # åå‰
        name = tbody.select_one('.is-fs18.is-fBold').text.strip().replace('\u3000', ' ')
        
        # ä½“é‡ (td[2] ã«ç™»éŒ²ç•ªå·/ç´šåˆ¥/æ°å/å‡ºèº«åœ°/å¹´é½¢/ä½“é‡ãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹)
        weight_match = re.search(r'([\d\.]+)kg', tds[2].text)
        weight = float(weight_match.group(1)) if weight_match else 0.0

        # å¹³å‡ST (td[3] ã®æœ€å¾Œã®ä¸€è¡Œ)
        st_txt = [x.strip() for x in tds[3].text.split('\n') if x.strip()]
        
        # ãƒ¢ãƒ¼ã‚¿ãƒ¼ç•ªå·ã¨2é€£ç‡ (td[6])
        mot = [x.strip() for x in tds[6].text.split('\n') if x.strip()]
        
        race_data["racelist"][b_no].update({
            "name": name, 
            "class": rank, 
            "weight": weight, 
            "motor_no": mot[0] if mot else '-',
            "motor_2ren": mot[1] if len(mot)>1 else '-', 
            "avg_st": extract_float(st_txt[-1]) if st_txt else 0.0
        })

def get_beforeinfo(jcd, rno, hd, race_data):
    url = f"https://www.boatrace.jp/owpc/pc/race/beforeinfo?rno={rno}&jcd={jcd}&hd={hd}"
    res = requests.get(url, headers=HEADERS); res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')
    env = race_data["environment"]
    
    # æ°´é¢æ°—è±¡æƒ…å ±ã®æŠ½å‡º
    t_el = soup.select_one('.is-direction .weather1_bodyUnitLabelData')
    if t_el: env['temperature'] = extract_float(t_el.text)
    w_el = soup.select_one('.is-weather .weather1_bodyUnitLabelTitle')
    if w_el: env['weather'] = w_el.text.strip()
    ws_el = soup.select_one('.is-wind .weather1_bodyUnitLabelData')
    if ws_el: env['wind_speed'] = extract_float(ws_el.text)
    wt_el = soup.select_one('.is-waterTemperature .weather1_bodyUnitLabelData')
    if wt_el: env['water_temp'] = extract_float(wt_el.text)
    wh_el = soup.select_one('.is-wave .weather1_bodyUnitLabelData')
    if wh_el: env['wave_height'] = extract_float(wh_el.text)

    # é¢¨å‘ã
    wd_img = soup.select_one('.is-windDirection .weather1_bodyUnitImage')
    if wd_img and wd_img.has_attr('class'):
        for cls in wd_img['class']:
            if cls.startswith('is-wind') and cls != 'is-windDirection':
                num = int(cls.replace('is-wind', ''))
                dir_map = {i: "è¿½ã„é¢¨" if i in [1,2,3,4,14,15,16] else "æ¨ªé¢¨" if i in [5,13] else "å‘ã‹ã„é¢¨" for i in range(1,17)}
                env['wind_direction'] = dir_map.get(num, "ç„¡é¢¨")
    if env.get('wind_speed') == 0.0: env['wind_direction'] = "ç„¡é¢¨"

    # å±•ç¤ºã‚¿ã‚¤ãƒ ãƒ»ãƒãƒ«ãƒˆ
    for tbody in soup.select('.table1 tbody.is-fs12'):
        tds = tbody.find_all('tr')[0].find_all('td')
        if len(tds) >= 6:
            b_no = str(int(tds[0].text.strip()))
            race_data["racelist"][b_no].update({
                "exhibition_time": extract_float(tds[4].text), 
                "tilt": extract_float(tds[5].text)
            })

    # ã‚¹ã‚¿ãƒ¼ãƒˆå±•ç¤ºã®è§£æ
    st_ex_divs = soup.select('.table1_boatImage1')
    for course_idx, div in enumerate(st_ex_divs, 1):
        b_no_el = div.select_one('.table1_boatImage1Number')
        st_time_el = div.select_one('.table1_boatImage1Time')
        if b_no_el and st_time_el:
            b_no_match = re.search(r'\d+', b_no_el.text)
            if b_no_match:
                b_no = b_no_match.group()
                st_val = st_time_el.text.strip()
                race_data["racelist"][b_no].update({
                    "start_course": course_idx,
                    "start_exhibition_st": st_val
                })

def fetch_all_odds(jcd, rno, hd, race_data):
    # é€£ç•ªç³»ã‚ªãƒƒã‚º (3é€£å˜, 3é€£è¤‡, 2é€£å˜, 2é€£è¤‡)
    for otype in ['odds3t', 'odds3f', 'odds2tf']:
        res = requests.get(f"https://www.boatrace.jp/owpc/pc/race/{otype}?rno={rno}&jcd={jcd}&hd={hd}")
        soup = BeautifulSoup(res.text, 'html.parser')
        tbs = soup.select('tbody.is-p3-0')
        if otype == 'odds3t': key, sep = '3é€£å˜', '-'
        elif otype == 'odds3f': key, sep = '3é€£è¤‡', '='
        
        if 'odds3' in otype:
            tb = tbs[0] if tbs else None
            if not tb: continue
            cur_snd, rem_row = [None]*6, [0]*6
            for row in tb.select('tr'):
                tds = row.find_all('td'); idx = 0
                for c in range(6):
                    if idx >= len(tds): break
                    if rem_row[c] == 0:
                        snd_td, trd_td, o_td = tds[idx], tds[idx+1], tds[idx+2]; idx += 3
                        cur_snd[c], rem_row[c] = snd_td, int(snd_td.get('rowspan', 1))
                    else:
                        trd_td, o_td = tds[idx], tds[idx+1]; idx += 2; snd_td = cur_snd[c]
                    rem_row[c] -= 1
                    if "is-disabled" not in o_td.get('class', []):
                        race_data["odds"][key][f"{c+1}{sep}{snd_td.text.strip()}{sep}{trd_td.text.strip()}"] = extract_float(o_td.text)
        else:
            for i, k in enumerate(["2é€£å˜", "2é€£è¤‡"]):
                if len(tbs) > i:
                    s = '-' if i == 0 else '='
                    for row in tbs[i].select('tr'):
                        tds = row.find_all('td')
                        for c in range(6):
                            if c*2+1 < len(tds) and "is-disabled" not in tds[c*2].get('class', []):
                                race_data["odds"][k][f"{c+1}{s}{tds[c*2].text.strip()}"] = extract_float(tds[c*2+1].text)

    # æ‹¡é€£è¤‡
    resk = requests.get(f"https://www.boatrace.jp/owpc/pc/race/oddsk?rno={rno}&jcd={jcd}&hd={hd}")
    tbk = BeautifulSoup(resk.text, 'html.parser').select_one('tbody.is-p3-0')
    if tbk:
        for row in tbk.select('tr'):
            tds = row.find_all('td')
            for c in range(6):
                if c*2+1 < len(tds) and "is-disabled" not in tds[c*2].get('class', []):
                    race_data["odds"]["æ‹¡é€£è¤‡"][f"{c+1}={tds[c*2].text.strip()}"] = tds[c*2+1].text.strip()

    # å˜å‹ãƒ»è¤‡å‹
    res_tf = requests.get(f"https://www.boatrace.jp/owpc/pc/race/oddstf?rno={rno}&jcd={jcd}&hd={hd}")
    soup_tf = BeautifulSoup(res_tf.text, 'html.parser')
    
    for unit in soup_tf.select('.grid_unit'):
        label_el = unit.select_one('.title7_mainLabel')
        if not label_el: continue
        
        label_text = label_el.text
        mode = "å˜å‹" if "å˜å‹" in label_text else "è¤‡å‹" if "è¤‡å‹" in label_text else None
        if not mode: continue
        
        for tr in unit.select('table tbody tr'):
            tds = tr.select('td')
            if len(tds) < 3: continue
            b_no = tds[0].text.strip()
            val = tds[2].text.strip()
            if "is-disabled" not in tds[2].get('class', []):
                if mode == "å˜å‹":
                    race_data["odds"]["å˜å‹"][b_no] = extract_float(val)
                else:
                    race_data["odds"]["è¤‡å‹"][b_no] = val

# --- UI & è§£æãƒ­ã‚¸ãƒƒã‚¯ ---
st.title("ğŸš€ Real-Time Physics Trader v2.2")

with st.sidebar:
    st.header("Race Settings")
    input_jcd = st.selectbox("é–‹å‚¬å ´", list(JCD_MAP.keys()))
    target_rno = st.number_input("ãƒ¬ãƒ¼ã‚¹ç•ªå·(R)", 1, 12, 12)
    target_date = st.date_input("æ—¥ä»˜", datetime.now()).strftime('%Y%m%d')
    execute = st.button("ç‰©ç†è§£æã‚¨ãƒ³ã‚¸ãƒ³ èµ·å‹•")

if execute:
    target_jcd = JCD_MAP[input_jcd]
    race_data = {
        "metadata": {"date": target_date, "stadium": input_jcd, "race_number": f"{target_rno}R"},
        "environment": {}, "racelist": {str(i): {} for i in range(1, 7)},
        "odds": {"3é€£å˜": {}, "3é€£è¤‡": {}, "2é€£å˜": {}, "2é€£è¤‡": {}, "æ‹¡é€£è¤‡": {}, "å˜å‹": {}, "è¤‡å‹": {}}
    }

    with st.status("åŒæœŸä¸­...", expanded=True) as status:
        get_racelist(target_jcd, target_rno, target_date, race_data)
        get_beforeinfo(target_jcd, target_rno, target_date, race_data)
        fetch_all_odds(target_jcd, target_rno, target_date, race_data)
        status.update(label="è§£ææº–å‚™å®Œäº†", state="complete")

    # --- JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’æœ€ä¸Šéƒ¨ã«ç§»å‹• ---
    json_export = json.dumps(race_data, ensure_ascii=False, indent=2)
    st.download_button(
        label="ğŸ“¥ AIè§£æç”¨JSONã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=json_export,
        file_name=f"{target_date}_{input_jcd}_{target_rno}R_AIãƒ‡ãƒ¼ã‚¿.json",
        mime="application/json"
    )

    # --- ç‰©ç†ãƒ¬ãƒãƒ¼ãƒˆ ---
    st.header("ğŸ›¡ï¸ Physics Analysis Report")
    
    b1 = race_data["racelist"]["1"]
    if b1.get('exhibition_time', 0) > 0:
        ex_times = [race_data["racelist"][str(i)].get('exhibition_time', 0) for i in range(1,7) if race_data["racelist"][str(i)].get('exhibition_time', 0) > 0]
        if ex_times and b1.get('exhibition_time', 0) == max(ex_times):
            st.error("ğŸ“‰ Conditional Renormalization: 1å·è‰‡ã«ç‰©ç†çš„æ¬ é™¥ã‚’æ¢çŸ¥ã€‚ç¢ºç‡ç©ºé–“ã‚’å†è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚")

    cols = st.columns(6)
    for i in range(1, 7):
        b = race_data["racelist"][str(i)]
        with cols[i-1]:
            ex_time = b.get('exhibition_time', 0)
            st.metric(f"{i}å·è‰‡", f"{ex_time}s")
            
            # --- å±•ç¤ºã‚¿ã‚¤ãƒ 0.0ã®ã‚¢ãƒ©ãƒ¼ãƒˆ ---
            if ex_time == 0 or ex_time == 0.0:
                st.warning("âš ï¸ è¨ˆæ¸¬ä¸èƒ½")
            
            st.write(f"å±•ç¤ºé€²å…¥: {b.get('start_course', '-')}ã‚³ãƒ¼ã‚¹")
            st.write(f"å±•ç¤ºST: {b.get('start_exhibition_st', '-')}")
            st.caption(f"{b.get('name')} ({b.get('class', '-')}) / {b.get('weight', 0.0)}kg")
            
            if i < 6:
                next_b = race_data["racelist"][str(i+1)]
                if abs(b.get('avg_st', 0) - next_b.get('avg_st', 0)) >= 0.08:
                    st.warning("âš ï¸ Void")
            
            if i > 1:
                prev_b = race_data["racelist"][str(i-1)]
                diff = prev_b.get('exhibition_time', 0) - b.get('exhibition_time', 0)
                if diff >= 0.07: st.error("ğŸŒŠ Wake Rejection")
                elif diff <= 0.06 and b.get('class') == 'A1': st.success("âš¡ Skill Offset")

    st.subheader("Raw AI Data")
    st.json(race_data)
