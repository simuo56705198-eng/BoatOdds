import streamlit as st
import requests
import json
import re
from bs4 import BeautifulSoup
from datetime import datetime

# --- åˆæœŸè¨­å®š ---
st.set_page_config(page_title="Real-Time Physics Trader v2.2", layout="wide")
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
JCD_MAP = {
    "æ¡ç”Ÿ": "01", "æˆ¸ç”°": "02", "æ±Ÿæˆ¸å·": "03", "å¹³å’Œå³¶": "04", "å¤šæ‘©å·": "05",
    "æµœåæ¹–": "06", "è’²éƒ¡": "07", "å¸¸æ»‘": "08", "æ´¥": "09",
    "ä¸‰å›½": "10", "ã³ã‚ã“": "11", "ä½ä¹‹æ±Ÿ": "12", "å°¼å´": "13",
    "é³´é–€": "14", "ä¸¸äº€": "15",
    "å…å³¶": "16", "å®®å³¶": "17", "å¾³å±±": "18", "ä¸‹é–¢": "19",
    "è‹¥æ¾": "20", "èŠ¦å±‹": "21", "ç¦å²¡": "22", "å”æ´¥": "23", "å¤§æ‘": "24"
}

def extract_float(text):
    m = re.search(r'[\d\.]+', text)
    return float(m.group()) if m else 0.0

# --- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ç¾¤ ---

def get_racelist(jcd, rno, hd, race_data):
    url = f"https://www.boatrace.jp/owpc/pc/race/racelist?rno={rno}&jcd={jcd}&hd={hd}"
    res = requests.get(url, headers=HEADERS)
    res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')
    tbodies = soup.select('.table1.is-tableFixed__3rdadd tbody.is-fs12')
    if not tbodies: return
    for tbody in tbodies:
        tds = tbody.find_all('tr')[0].find_all('td')
        if len(tds) < 8: continue
        boat_no = str(int(tds[0].text.strip()))
        name = tbody.select_one('.is-fs18.is-fBold').text.strip().replace('\u3000', ' ')
        class_rank = tbody.select_one('.is-fColor1').text.strip() if tbody.select_one('.is-fColor1') else ""
        st_list = [x.strip() for x in tds[3].text.split('\n') if x.strip()]
        mot = [x.strip() for x in tds[6].text.split('\n') if x.strip()]
        race_data["racelist"][boat_no].update({
            "name": name, "class": class_rank, 
            "motor_no": mot[0] if mot else '-', "motor_2ren": mot[1] if len(mot)>1 else '-', 
            "avg_st": extract_float(st_list[-1]) if st_list else 0.0
        })

def get_beforeinfo(jcd, rno, hd, race_data):
    url = f"https://www.boatrace.jp/owpc/pc/race/beforeinfo?rno={rno}&jcd={jcd}&hd={hd}"
    res = requests.get(url, headers=HEADERS)
    res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')
    
    env = {"weather": "ä¸æ˜", "wind_direction": "ç„¡é¢¨", "wind_speed": 0.0, "temperature": 0.0, "water_temp": 0.0, "wave_height": 0.0}
    t_el = soup.select_one('.is-direction .weather1_bodyUnitLabelData')
    if t_el: env['temperature'] = extract_float(t_el.text)
    
    ws_el = soup.select_one('.is-wind .weather1_bodyUnitLabelData')
    if ws_el: env['wind_speed'] = extract_float(ws_el.text)
    
    # é¢¨å‘ãåˆ¤å®š
    wd_img = soup.select_one('.is-windDirection .weather1_bodyUnitImage')
    if wd_img and wd_img.has_attr('class'):
        for cls in wd_img['class']:
            if cls.startswith('is-wind') and cls != 'is-windDirection':
                num = cls.replace('is-wind', '')
                if num.isdigit():
                    dir_map = {1: "è¿½ã„é¢¨", 2: "å³æ–œã‚è¿½ã„é¢¨", 5: "å³æ¨ªé¢¨", 9: "å‘ã‹ã„é¢¨", 13: "å·¦æ¨ªé¢¨"} # ç°¡ç•¥åŒ–
                    env['wind_direction'] = dir_map.get(int(num), "æ–œã‚é¢¨")
    
    race_data["environment"] = env

    for tbody in soup.select('.table1 tbody.is-fs12'):
        tds = tbody.find_all('tr')[0].find_all('td')
        if len(tds) < 6: continue
        boat_no = str(int(tds[0].text.strip()))
        race_data["racelist"][boat_no].update({
            "exhibition_time": extract_float(tds[4].text),
            "tilt": extract_float(tds[5].text)
        })

# --- UIæ§‹ç¯‰ ---
st.title("ğŸš€ Real-Time Physics Trader v2.2")

with st.sidebar:
    st.header("Race Settings")
    input_jcd = st.selectbox("é–‹å‚¬å ´", list(JCD_MAP.keys()))
    target_rno = st.number_input("ãƒ¬ãƒ¼ã‚¹ç•ªå·(R)", 1, 12, 12)
    target_date = st.date_input("æ—¥ä»˜", datetime.now()).strftime('%Y%m%d')
    execute = st.button("ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ»è§£æé–‹å§‹")

if execute:
    target_jcd = JCD_MAP[input_jcd]
    race_data = {
        "metadata": {"date": target_date, "stadium": input_jcd, "race_number": f"{target_rno}R"},
        "environment": {},
        "racelist": {str(i): {} for i in range(1, 7)},
        "odds": {"3é€£å˜": {}}
    }

    with st.spinner("ç‰©ç†ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­..."):
        get_racelist(target_jcd, target_rno, target_date, race_data)
        get_beforeinfo(target_jcd, target_rno, target_date, race_data)

    # --- ç‰©ç†ã‚¨ãƒ³ã‚¸ãƒ³è§£æ (å›ºæœ‰ãƒ­ã‚¸ãƒƒã‚¯é©ç”¨) ---
    st.header("ğŸ›¡ï¸ Physics Analysis Report")
    
    cols = st.columns(6)
    for i in range(1, 7):
        b = race_data["racelist"][str(i)]
        with cols[i-1]:
            st.metric(f"{i}å·è‰‡", f"{b.get('exhibition_time', 0)}s")
            st.caption(f"{b.get('name', 'ä¸æ˜')} ({b.get('class', '-')})")
            
            # 1. Deterministic Void (çœŸç©ºåˆ¤å®š)
            avg_st = b.get('avg_st', 0)
            if i < 6:
                next_st = race_data["racelist"][str(i+1)].get('avg_st', 0)
                if abs(avg_st - next_st) >= 0.08:
                    st.warning("âš ï¸ Void Detected")

    # --- ç‰©ç†ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒª ---
    st.subheader("Raw Data")
    col_env, col_raw = st.columns([1, 2])
    with col_env:
        st.write("**Environment**")
        st.json(race_data["environment"])
    with col_raw:
        st.write("**Race List**")
        st.json(race_data["racelist"])
